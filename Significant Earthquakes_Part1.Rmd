---
title: "Machine Learning 1 - Statistical Analysis and Prediction of Significant Earthquakes"
author: "Esin, Andrea and Sabrina"
date: "2023-06-09"
output: html_document
---

# Table of contents
1. [Introduction](#Introduction)  
    1.1. [Description of our data](#Description of our data)  
    1.2. [Getting the data](#Getting the data)  
    1.3. [Cleaning the data](#Cleaning the data)  
2. [Graphical Analysis](#Graphical Analysis)  
    2.1 [Map of earthquakes](#Map of earthquakes)  
3. [Linear Model](#Linear Model)
    3.1.
    3.2.
    3.3.
4. [Generalised Linear Model Poisson](#Generalised Linear Model Poisson)    
5. [Generalised Linear Model Binomial](#Generalised Linear Model Binomial)  
6. [Generalised Additive Model](#Generalised Additive Model)  
7. [Neural Network](#Neural Network)  
8. [Support Vector Machine](#Support Vector Machine)  
9. [Optimisation Problem](#Optimisation Problem)  
10. [Conclusion](#Conclusionn)  


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r imports, message = FALSE, error = FALSE, warning = FALSE, eval = TRUE, echo = TRUE, include = FALSE}

#We are listing here all the libraries used in this document, however all of them will be stated again and reloaded directly in the schunks where they are needed to overcome knitting issues.

#library(dplyr)
#library("tidyr")
#library("rnaturalearth")
#library("rnaturalearthdata")
#library("sf")
#library("ggplot2")
#library(ggcorrplot)
#install.packages("olsrr")
#library("olsrr")
#library("cowplot")

```


<br>

## 1. Introduction <a name="introduction"></a>

Earthquakes are one of the most destructive natural disasters that can strike without warning, causing extensive damage to infrastructure, loss of life, and massive economic losses. While we cannot prevent earthquakes from occurring, the ability to accurately predict when and where they might occur could save countless lives and minimize the damage caused. 

Therefore, our aim with this report is to contribute the significant earthquake prediction which enables to provide advanced warning of potentially catastrophic seismic events, allowing governments and communities to prepare and take necessary measures to minimize the impact of such events. 

<br>

#### 1.1.Description of our data <a name="Description of our data"></a>

**Data source: https://www.ngdc.noaa.gov/hazel/view/hazards/earthquake/search**

The Significant Earthquake Database contains information on destructive earthquakes from 2150 B.C. to the present that meet at least one of the following criteria: Moderate damage (approximately $1 million or more), 10 or more deaths, Magnitude 7.5 or greater, Modified Mercalli Intensity X or greater, or the earthquake generated a tsunami. The database can also be displayed and extracted with the Natural Hazards Interactive Map.

<br>

Below we are listing a short summary of our main variables.
At the primary and secondary deaths and damages where available the total numbers have been added to the dataset, in the "description" field the variables have already been clustered.  

<br>

<button type="button" class="collapsible">**Earthquake Magnitude [Mag] **</button>
<div class="content">
  <p>

Valid values: 0.0 to 9.9

The value in this column contains the primary earthquake magnitude. Magnitude measures the energy released at the source of the earthquake. Magnitude is determined from measurements on seismographs. For pre-instrumental events, the magnitudes are derived from intensities. There are several different scales for measuring earthquake magnitudes. The primary magnitude is chosen from the available magnitude scales in this order:

Mw Magnitude  
Ms Magnitude  
Mb Magnitude  
Ml Magnitude  
Mfa Magnitude  
Unknown Magnitude  
 
 </p>
</div>
<br>

<button type="button" class="collapsible">**Modified Mercalli Intensity Scale [MMI.Int]**</button>
<div class="content">
  <p>
  
Valid values: 1 to 12

The Modified Mercalli Intensity (Int) is given in Roman Numerals (converted to numbers in the digital database). An interpretation of the values is listed below.

Table 1. Modified Mercalli Intensity Scale of 1931  

I.	Not felt except by a very few under especially favorable circumstances.  
II.	Felt only by a few persons at rest, especially on upper floors of buildings. Delicately suspended objects may swing.  

III.	Felt quite noticeably indoors, especially on upper floors of buildings, but many people do not recognize it as an earthquake. Standing motor cars may rock slightly. Vibration like passing truck. Duration estimated.  

IV.	During the day felt indoors by many, outdoors by few. At night some awakened. Dishes, windows, and doors disturbed; walls make creaking sound. Sensation like heavy truck striking building. Standing motorcars rock noticeably.  

V.	Felt by nearly everyone; many awakened. Some dishes, windows, etc., broken; a few instances of cracked plaster; unstable objects overturned. Disturbance of trees, poles, and other tall objects sometimes noticed. Pendulum clocks may stop.  

VI.	Felt by all; many frightened and run outdoors. Some heavy furniture moved; a few instances of fallen plaster or damaged chimneys. Damage slight.  

VII.	Everybody runs outdoors. Damage negligible in buildings of good design and construction slight to moderate in well built ordinary structures; considerable in poorly built or badly designed structures. Some chimneys broken. Noticed by persons driving motor cars.  

VIII.	Damage slight in specially designed structures; considerable in ordinary substantial buildings, with partial collapse; great in poorly built structures. Panel walls thrown out of frame structures. Fall of chimneys, factory stacks, columns, monuments, walls. Heavy furniture overturned. Sand and mud ejected in small amounts. Changes in well water. Persons driving motor cars disturbed.  

IX.	Damage considerable in specially designed structures; well-designed frame structures thrown out of plumb; great in substantial buildings, with partial collapse. Buildings shifted off foundations. Ground cracked conspicuously. Underground pipes broken.  

X.	Some well-built wooden structures destroyed; most masonry and frame structures destroyed with foundations; ground badly cracked. Rails bent. Landslides considerable from river banks and steep slopes. Shifted sand and mud. Water splashed over banks.  

XI.	Few, if any (masonry), structures remain standing. Bridges destroyed. Broad fissures in ground. Underground pipelines completely out of service. Earth slumps and land slips in soft ground. Rails bent greatly.  

XII.	Damage total. Waves seen on ground surfaces. Lines of sight and level distorted. Objects thrown upward into the air.  

 </p>
</div>
<br>

<button type="button" class="collapsible">**Focal Depth (km) [Focal.Depth..km.]**</button>
<div class="content">
  <p>

The depth of the earthquake is given in kilometers.

 </p>
</div>
<br>

<button type="button" class="collapsible">**Hazard Association**</button>
<div class="content">
  <p>

**Associated Tsunami or Seiche [Tsu]**  
When a tsunami or seiche was generated by an earthquake, An icon appears in the Associated Tsunami column which is linked to the tsunami event database. The link will display additional tsunami event information.  

**Volcano [Vol]**  
The Volcano link will display additional information if the earthquake was associated with a volcanic eruption. The information may include information such as the VEI index, morphology, and the effects of the eruption.
  
 </p>
</div>
<br>

<button type="button" class="collapsible">**Earthquake Effects**</button>
<div class="content">
  <p>

**Description of Deaths from the Earthquake [Death.Description]**    

Valid values: 0 to 4  

When a description was found in the historical literature instead of an actual number of deaths, this value was coded and listed in the Deaths column. If the actual number of deaths was listed, a descriptor was also added for search purposes.  

0	None  
1	Few (~1 to 50 deaths)  
2	Some (~51 to 100 deaths)  
3	Many (~101 to 1000 deaths)  
4	Very many (over 1000 deaths)  

**Description of Damage from the Earthquake [Damage.Description]**  

Valid values: 0 to 4  

For those events not offering a monetary evaluation of damage, the following five-level scale was used to classify damage (1990 dollars) and was listed in the Damage column. If the actual dollar amount of damage was listed, a descriptor was also added for search purposes.  

0	NONE  
1	LIMITED (roughly corresponding to less than $1 million)  
2	MODERATE (~$1 to $5 million)  
3	SEVERE (~$5 to $25 million)  
4	EXTREME (~$25 million or more)  

**[Missing.Description]**  
**[Injuries.Description]**  
**[Houses.Destroyed.Description]**  
**[Houses.Damaged.Description]**  

 </p>
</div>
<br>

<button type="button" class="collapsible">**Total Earthquake and Secondary Effects**</button>
<div class="content">
  <p>
**Description of Deaths from the Earthquake and secondary effects (eg Tsunami)**  
Valid values: 0 to 4  

When a description was found in the historical literature instead of an actual number of deaths, this value was coded and listed in the Deaths column. If the actual number of deaths was listed, a descriptor was also added for search purposes.  

0	None  
1	Few (~1 to 50 deaths)  
2	Some (~51 to 100 deaths)  
3	Many (~101 to 1000 deaths)  
4	Very many (over 1000 deaths) 

**[Total.Death.Description]**  
**[Total.Missing.Description]**  
**[Total.Injuries.Description]**  
**[Total.Damage...Mil.]**  
**[Total.Houses.Destroyed.Description]**  
**[Total.Houses.Damaged.Description]**  
 </p>
</div>
<br>


#### 1.2.Getting the data <a name="Getting the data"></a>

We first setting the working directory, than we are loading the tab separated data file to R.


```{r getting data, message=FALSE, warning=FALSE, eval = TRUE, echo = TRUE, include=TRUE}

setwd("C:/Users/A/Documents/FS23_ML1/Project Data/Git_repository/ML01")
eqdata <- read.csv("significant-earthquake-database.tsv", header = TRUE, sep = "\t")

```

At first we will have a look at the data provided:

<button type="button" class="collapsible">**str data (interactive dropdown button)**</button>
<div class="content">
  <p>

```{r overview1, message = FALSE, error = FALSE, warning = FALSE, eval = TRUE, echo = TRUE, include = TRUE}

str(eqdata)

```

The original data set has 6365 observations of 39 variables.

  </p>
</div>
<br>


#### 1.3 Cleaning the data <a name="Cleaning the data"></a>

After loading we have decided to perform the below cleaning our dataset:

**Exclude data dated before 1800**

- Our reasons are the following:

  * data available mostly from historical records therefore less reliable

  * the measurement quality is not reliable based on less developed methods

  * we had a lot of missing values from these records

**Exclude data where magnitude is not available**

- * the variable of magnitude has key importance in our analysis, the records where it is missing we cannot trust.


```{r cleaning, message = FALSE, error = FALSE, warning = FALSE, eval = TRUE, echo = TRUE, include = TRUE}

library(dplyr)

eqdata <- eqdata %>% filter(Year >= 1800)
eqdata <- eqdata %>% filter(!is.na(Mag))
sum(is.na(eqdata$Mag))

```

<br>

<button type="button" class="collapsible">**str cleaned data (interactive dropdown button)**</button>
<div class="content">
  <p>

```{r overview3, message = FALSE, error = FALSE, warning = FALSE, eval = TRUE, echo = TRUE, include = TRUE}

str(eqdata)

```

The original data set has 6365 observations of 39 variables.

  </p>
</div>
<br>

After cleaning the dataset we have **4028 observations of  39 variables** remaining. We will perform all the following analysis with this dataset.

<br>

## 2. Graphical Analysis <a name="Graphical Analysis"></a>

<br>

#### 2.1 Map of earthquakes <a name="Map of earthquakes"></a>

```{r map, message = FALSE, error = FALSE, warning = FALSE, eval = TRUE, echo = TRUE, include = TRUE}

library("rnaturalearth")
library("rnaturalearthdata")
library("sf")
library("ggplot2")

world <- ne_countries(scale = "medium", returnclass = "sf")
class(world)


```

<br>

## 3. Linear Model <a name="Linear Model"></a>

<br>

#### 3.1 Characteristics of a linear model

Linear regression models are unsupervised models, which means we want to predict how the dependent variable changes with changing the independent variables. Regression models the dependent variable takes quantitative measures.(this means Y value is an increasing or decreasing number whith changing the value of the dependent variables.)

Generally linear models are never completely correct, but the interpretability of the linear model is relatively high compared to other more complex models. The danger of overfitting is generally less with linear models.

Linear regression can be performed with fitting a single predictor or a multiple predictors variables at the same time. Generally one starts with fitting all the relevant predictors.This is the reason, we start our statistical analysis with a multiple linear regression below.

<br>

#### 3.2 Our research questions

The scope of this analysis is to be able to make predictions about number of deaths caused by earthquakes. This is to understand how magnitude, intensity, focal depth,time and location correspond to the total number of deaths by earthquakes.

We are going to look at which independent variables have an effect on the:  

 - Y1: total number of deaths (with secondary effects):  
 [Total.Damage...Mil.]    
 - Y2: total cost of damage (USD) (with secondary effects):  
 [Total.Deaths]
 
Remark: We are going to use the backward evaluation model, which means we are fitting all relevant the independent variables available in our data set, and removing them one by one looking at how the significance changes.

In both cases we will examine the below independent variables:  
 
 - magnitude [Mag]  
 
 - intensity [MMI.Int]
  
 - focal depth [Focal.Depth..km]
 
 - Year [Year]: Remark: month, date, day hour and sec we do not include, given we do not see an added value here.
 
 - Location [Latitude],[Longitude]
 
 - Volcano, Tsunami: [Vol],[Tsu]
 
 - Location name: We do not include this either, given it would lead to too many levels, which is problematic using linear regression. We have the Lattitude and longitude, included which has an indication on location.

 
 <br>

#### 3.3 Data Cleaning and fitting linear model

Total Death numbers, total damage costs, intensity and focal depth are not available in each row of our data set. Given we cannot predict these values we have decided to remove the rows, where any of these values is NA. We are also turning NA`s in Tsu and Vol column to 0 in order we can fit the linear model below.


```{r linear regression 0, message = FALSE, error = FALSE, warning = FALSE, eval = TRUE, echo = FALSE, include = FALSE}

library("dplyr")
library("tidyr")

# Piping total death to remove NAs from columns total death, magnitude,intensity and focal depth

eqdata.no.na.total.death <- eqdata %>%
  select(Year, Total.Deaths,Total.Death.Description,Mag, MMI.Int, Focal.Depth..km., Vol, Tsu, Location.Name, Longitude, Latitude)%>%
  filter(!is.na(Total.Deaths))%>%
  filter(!is.na(MMI.Int))%>%
  filter(!is.na(Focal.Depth..km.))%>%
  mutate_at(c("Vol", "Tsu"), ~replace_na(., 0))
  
#Our filtered data set contains so many rows:
linear.count.rows.death <- sum(!is.na(eqdata.no.na.total.death$Total.Deaths))

str(eqdata.no.na.total.death)

```

  - Our final data set eqdata.no.na.total.death has `r linear.count.rows.death` rows.  
  
<br>

  
```{r linear regression fit model death1, message = FALSE, error = FALSE, warning = FALSE, eval = TRUE, echo = FALSE, include = TRUE}

lm.all.death <- lm(Total.Deaths ~ Mag + MMI.Int + Focal.Depth..km. + Year + Vol + Tsu + Latitude + Longitude, data = eqdata.no.na.total.death)
summary(lm.all.death)

 
```

<br>

Above we can see the Adjusted R2 value is 0.0526, which means that our model explains only 6 % the relationship of the variables. This is a very low result. 

The individual variables except 2 of them are larger than 0.005 which indicates, that they do not seem to have a meaningful effect on our dependent variable. 

In the code below, we will be removing them one by one, and will not comment those results where the results do not change meaningfully. 


```{r linear regression fit model death2, message = FALSE, error = FALSE, warning = FALSE, eval = TRUE, echo = FALSE, include = FALSE}

lm.all.death1 <- lm(Total.Deaths ~ Mag + MMI.Int + Focal.Depth..km. + Vol + Tsu + Latitude + Longitude, data = eqdata.no.na.total.death)
summary(lm.all.death1)

lm.all.death2 <- lm(Total.Deaths ~ Mag + MMI.Int + Focal.Depth..km. +  Tsu + Latitude + Longitude, data = eqdata.no.na.total.death)
summary(lm.all.death2)

lm.all.death3 <- lm(Total.Deaths ~ Mag + MMI.Int + Focal.Depth..km. + Latitude + Longitude, data = eqdata.no.na.total.death)
summary(lm.all.death3)

lm.all.death4 <- lm(Total.Deaths ~ Mag + MMI.Int + Latitude + Longitude, data = eqdata.no.na.total.death)
summary(lm.all.death4)

lm.all.death5 <- lm(Total.Deaths ~ Mag + MMI.Int + Longitude, data = eqdata.no.na.total.death)
summary(lm.all.death5)

```

As a result we end up keeping the Magnitude and Intensity which are the 2 independent variables which seem to be relevant for our model. 

<br>

```{r linear regression fit model death3, message = FALSE, error = FALSE, warning = FALSE, eval = TRUE, echo = FALSE, include = TRUE}

lm.all.death6 <- lm(Total.Deaths ~ Mag + MMI.Int, data = eqdata.no.na.total.death)
summary(lm.all.death6)

```

<br>

**Colinearity**  

Now we are looking at the correlation matrix, to check whether there is a collinearity between Magnitude and Intensity.

<br>

```{r linear regression fit model death4, message = FALSE, error = FALSE, warning = FALSE, eval = TRUE, echo = FALSE, include = TRUE}

# We create a new subset of our data wmit our 3 variables for the correlation matrix
death.mag.int <- eqdata.no.na.total.death %>%
  select(Total.Deaths, Mag, MMI.Int)

#create the correlation matrix
corr.matrix.death <- cor(death.mag.int)

# funktion creating the correlation matrix with gglot and corrplot
library(ggcorrplot)
library(ggplot2)

formated_ggcorrplot <- function(f_correlation_matrix) {
  ggcorrplot(f_correlation_matrix, show.legend = TRUE , sig.level=0.05, lab_size = 4.5,lab = TRUE,lab_col ="darkred", p.mat = NULL, 
             insig = c("pch", "blank"), pch = 1, pch.col = "black", pch.cex =1,
             tl.cex = 10) +
    theme(axis.text.x = element_text(margin=margin(-2,0,0,0)),  # Order: top, right, bottom, left
          axis.text.y = element_text(margin=margin(0,-2,0,0))) +
    geom_vline(xintercept=1:ncol(f_correlation_matrix)-0.5, colour="white", size=1) +
    geom_hline(yintercept=1:ncol(f_correlation_matrix)-0.5, colour="white", size=1)
}

formated_ggcorrplot(corr.matrix.death)

```

<br>

As we can see the correlation coefficients are not too high, so there is no colinearity between Magnitife and Intensity.

An other indicator to check this is the VIF value:
Which is not high either.

<br>

```{r linear regression fit model death5, message = FALSE, error = FALSE, warning = FALSE, eval = TRUE, echo = FALSE, include = TRUE}

library("olsrr")
ols_vif_tol (lm.all.death6)

```

<br>

Finally, let us check an interpret the coefficients of the linear model.

The intercept is below zero, which is very hard to interpret for our variable. This may not even make sens.

The coefficient for magnitude tells us, that with each unit increase of a magnitude the number of deaths increases with 1796.

The coefficient of the intensity, tells us, with unchanged value of the intercept and the magnitude, if the intensity is one unit higher, it is likely that the number of deaths increases additionnaly with 1471. 

<br>

#### 3.4 Graphical analysis Magnitude and Intensity

Let`s look at in 2 dimension, how our data plots Magnitude and Intensity plotted against the number of total deaths looks like:

<br>

```{r linear regression graph2D, message = FALSE, error = FALSE, warning = FALSE, eval = TRUE, echo = FALSE, include = TRUE}

library("ggplot2")
library("cowplot")


# Plot Magnitude vs. Total Death
plot.death.mag <- ggplot(eqdata.no.na.total.death,aes(Mag,Total.Deaths)) +
  geom_point() +
  geom_smooth(method='lm',se=FALSE)

# Plot Intensity vs. Total Death
plot.death.int <- ggplot(eqdata.no.na.total.death,aes(MMI.Int,Total.Deaths)) +
  geom_point() +
  geom_smooth(method='lm',se=FALSE)


plot_grid(plot.death.mag, plot.death.int, labels = "AUTO")

```

<br>

The blue line ia a regression line. We can see in both cases that our linear regresion line on both cases does not really fits to the data points especially at higher values of magnitude and Intensity. 

<br>

If we plot in 3D our data points, as well as the plaine, which visualizes our linear model, looking at the data we have the below assumptions:

1. There is non-linearity in our model
2. Data is not normally distributed
3. There is heteroskedasticity
4. The data contains outliers and high leverage points

<br>

```{r linear regression graph3D, message = FALSE, error = FALSE, warning = FALSE, eval = TRUE, echo = FALSE, include = TRUE}

 
library(plotly)
library(reshape2)

# Plot our datapoints in 3D
plot.all.death <- plot_ly(x=eqdata.no.na.total.death$Mag,
                          y=eqdata.no.na.total.death$MMI.Int,
                          z=eqdata.no.na.total.death$Total.Deaths,
                          type="scatter3d", 
                          mode="markers", 
                          color=eqdata.no.na.total.death$Total.Deaths)
plot.all.death

# Plot our datapoints in 3D with the regression plaine
lm.3D <- lm(Total.Deaths ~ 0 + Mag + MMI.Int, data = eqdata.no.na.total.death)

#Graph Resolution (more important for more complex shapes)
graph_reso <- 0.05

#Setup Axis
axis_x <- seq(min(eqdata.no.na.total.death$Mag), max(eqdata.no.na.total.death$Mag), by = graph_reso)
axis_y <- seq(min(eqdata.no.na.total.death$MMI.Int), max(eqdata.no.na.total.death$MMI.Int), by = graph_reso)

#Sample points
death_lm_surface <- expand.grid(Mag = axis_x,MMI.Int = axis_y,KEEP.OUT.ATTRS = F)
death_lm_surface$Total.Deaths <- predict.lm(lm.3D, newdata = death_lm_surface)
death_lm_surface <- acast(death_lm_surface, MMI.Int ~ Mag, value.var = "Total.Deaths") #y ~ x

plot.all.death2 <- plot_ly(eqdata.no.na.total.death,
                           x= ~Mag,
                           y= ~MMI.Int,
                           z= ~Total.Deaths,
                           type = "scatter3d",
                           color = ~Total.Deaths,
                           #colors = c("darkblue","grey","yellow"),
                           mode = "markers")

#Plot the plain of  our linear model in 3D
plot.all.death2 <- add_trace(p = plot.all.death2,
                       z = death_lm_surface,
                       x = axis_x,
                       y = axis_y,
                       type = "surface")

plot.all.death2

```

<br>

<br>
To investigate on our assumptions, we plot the residual against the fitted values.

Figure below for Magnitude vs. Total Death:

```{r linear regression fit model death6, message = FALSE, error = FALSE, warning = FALSE, eval = TRUE, echo = FALSE, include = TRUE}

par(mfrow=c(2,2))

lm.mag <- lm(Total.Deaths ~ Mag, data = eqdata.no.na.total.death)
plot(lm(Total.Deaths~Mag,data=eqdata.no.na.total.death, title ="Residual Magnitude vs. Total Death"))
```

<br>
Figure below for Intensity vs. Total Death:
<br>

```{r linear regression fit model death7, message = FALSE, error = FALSE, warning = FALSE, eval = TRUE, echo = FALSE, include = TRUE}

par(mfrow=c(2,2))

lm.int <- lm(Total.Deaths ~ MMI.Int, data = eqdata.no.na.total.death)
plot(lm(Total.Deaths~MMI.Int,data=eqdata.no.na.total.death, title ="Residual Intensity vs. Total Death"))

```

<br>

In both figures we can see 4 plots which we explain below:  

**Residuals vs Fitted Values**  

The red line is linear, however towards higher values majority of our data points start to be divide from the line. This is the place where we also have our outliers.This may indicate some non-lineriality in our data.  

**Normal Q-Q**

This chart we can see how the distribution of the data is. In case the most data points lie in the line, the data is normally distributed. 
In our case towards higher values the majority of our data points divergates from the line, this means that in our model the residuals aren’t Gaussian and thus your errors aren’t either, so our data is not normally distributed.  

**Scale Location**  

This chart we can see if there is heteroskedasticity in our data. On both charts, the red line is approximately horizontal, this means that the average magnitude of the standardized residuals isn’t changing much as a function of the fitted values.
However the distribution of the datapoints concentrates around the value 5000 and in lower and higher values we have significantly less datapoints. This indicates heteroskedasticity.   

**Residuals vs Leverage**  

In the plotted data we can already see that there are some data points "far" away, or outlying. This chart shows which outliers are high leverage points, which means their change or removal influences more our model as the other datapoints. At Magnitude as well as at Intensity we have few such a points which lie outside of the line indicating the Cook`s distance.

<br>
To sum up our findings above, we can conclude, that our linear model fitted with Intensity and Magnitude is not the best fit for predict the number of deaths caused by earthquakes. Therefoer below we are going to look at more complex models.

<br>

## 4. Generalised Linear Model Poisson <a name="Generalised Linear Model Poisson"></a>

<br>

## 5. Generalised Linear Model Binomial <a name="Generalised Linear Model Binomial"></a>

<br>

## 6. Generalised Additive Model <a name="Generalised Additive Model"></a>

Difference GLM vs. GAM
GAM do not assume a priori any specific form of this relationship, and can be used to reveal and estimate non-linear effects of the covariate on the dependent variable. 
<br>

## 7. Neural Network <a name="Neural Network"></a>

<br>

## 8. Support Vector Machine <a name="Support Vector Machine"></a>

<br>

## 9. Optimisation Problem <a name="Optimisation Problem"></a>

<br>

## 10. Conclusion <a name="Conclusion"></a>

<br>




<!--
=========================================
  Machinery for the collapsible sections.
=========================================

  References:
  -----------
  https://www.w3schools.com/howto/howto_js_collapsible.asp
https://www.w3schools.com/howto/tryit.asp?filename=tryhow_js_collapsible
-->
  
  <style>
  .collapsible {
    background-color: #2874A6;
      color: white;
    cursor: pointer;
    padding: 10px;
    width: 100%;
    border: none;
    text-align: left;
    outline: none;
    font-size: 15px;
  }

.active, .collapsible:hover {
  background-color: #2874A6;
}

.content {
  padding: 0 18px;
  display: none;
  overflow: hidden;
  background-color: #D6EAF8;
}
</style>
  
  
  <script>
  var coll = document.getElementsByClassName("collapsible");
var i;

for (i = 0; i < coll.length; i++) {
  coll[i].addEventListener("click", function() {
    this.classList.toggle("active");
    var content = this.nextElementSibling;
    if (content.style.display === "block") {
      content.style.display = "none";
    } else {
      content.style.display = "block";
    }
  });
}
</script>